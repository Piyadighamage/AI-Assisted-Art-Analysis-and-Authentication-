{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3260103,"sourceType":"datasetVersion","datasetId":1975222}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport re\nimport pickle\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:30:18.719927Z","iopub.execute_input":"2025-08-12T16:30:18.720643Z","iopub.status.idle":"2025-08-12T16:30:18.727854Z","shell.execute_reply.started":"2025-08-12T16:30:18.720609Z","shell.execute_reply":"2025-08-12T16:30:18.726333Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# File paths\nARTWORK_CSV = \"/kaggle/input/historic-art/complete/artwork_dataset.csv\"\nINFO_CSV = \"/kaggle/input/historic-art/complete/info_dataset.csv\"\nIMAGE_DIR = \"/kaggle/input/historic-art/complete/artwork\"\n\n# Load CSV files\nartwork_df = pd.read_csv(ARTWORK_CSV)\ninfo_df = pd.read_csv(INFO_CSV)\n\nprint(\"Artwork data sample:\")\nprint(artwork_df.head())\n\nprint(\"\\nArtist info sample:\")\nprint(info_df.head())\n\n# Merge on 'artist'\ndf = artwork_df.merge(info_df, on=\"artist\", how=\"left\")\nprint(f\"Total records after merge: {len(df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:30:32.954564Z","iopub.execute_input":"2025-08-12T16:30:32.955437Z","iopub.status.idle":"2025-08-12T16:30:33.251362Z","shell.execute_reply.started":"2025-08-12T16:30:32.955405Z","shell.execute_reply":"2025-08-12T16:30:33.250189Z"}},"outputs":[{"name":"stdout","text":"Artwork data sample:\n   ID            artist                               title  \\\n0   0  AACHEN, Hans von                    venus and adonis   \n1   1  AACHEN, Hans von                     procuring scene   \n2   2  AACHEN, Hans von  self-portrait with a glass of wine   \n3   3  AACHEN, Hans von    two laughing men (self-portrait)   \n4   4  AACHEN, Hans von       portrait of emperor rudolf ii   \n\n                                        picture data  \\\n0  1574-88, oil on canvas, 68 x 95 cm, fogg art m...   \n1  1605-10, oil on wood, 114 x 130 cm, kunsthisto...   \n2  c. 1596, oil on canvas, 53 x 44 cm, private co...   \n3  before 1574, oil on panel, 48 x 39 cm, archdio...   \n4  1606-08, oil on canvas, 60 x 48 cm, kunsthisto...   \n\n                       file info                                       jpg url  \n0  1700*1211, true color, 252 kb    https://www.wga.hu/art/a/aachen/adonis.jpg  \n1  1370*1168, true color, 212 kb   https://www.wga.hu/art/a/aachen/z_scene.jpg  \n2    896*1074, true color, 57 kb  https://www.wga.hu/art/a/aachen/selfport.jpg  \n3  1173*1500, true color, 210 kb  https://www.wga.hu/art/a/aachen/selfpor1.jpg  \n4  1149*1500, true color, 247 kb   https://www.wga.hu/art/a/aachen/rudolf2.jpg  \n\nArtist info sample:\n                   artist           born-died             period     school  \\\n0        AACHEN, Hans von         (1552-1615)          Mannerism    painter   \n1  AAGAARD, Carl Frederik         (1833-1895)            Realism    painter   \n2      ABADIA, Juan de la  (active 1470-1490)  Early Renaissance    painter   \n3            ABADIE, Paul         (1812-1884)        Art Nouveau  architect   \n4      ABAQUESNE, MassÃ©ot       (c 1500-1564)   High Renaissance     potter   \n\n                                             url        base nationality  \n0    https://www.wga.hu/html/a/aachen/index.html     Germany      German  \n1   https://www.wga.hu/html/a/aagaard/index.html  Copenhagen      Danish  \n2    https://www.wga.hu/html/a/abadia/index.html      Huesca     Spanish  \n3    https://www.wga.hu/html/a/abadie/index.html       Paris      French  \n4  https://www.wga.hu/html/a/abaquesn/index.html      France      French  \nTotal records after merge: 45600\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"if 'ID' in df.columns:\n    df['image_path'] = df['ID'].apply(lambda x: os.path.join(IMAGE_DIR, f\"{x}.jpg\"))\nelif 'id' in df.columns:\n    df['image_path'] = df['id'].apply(lambda x: os.path.join(IMAGE_DIR, f\"{x}.jpg\"))\nelse:\n    raise Exception(\"No 'ID' or 'id' column found for image filenames!\")\n\n# Filter to keep only rows with existing images\ndf = df[df['image_path'].apply(os.path.exists)].reset_index(drop=True)\nprint(f\"Records with existing images: {len(df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:30:47.918379Z","iopub.execute_input":"2025-08-12T16:30:47.918710Z","iopub.status.idle":"2025-08-12T16:31:43.711268Z","shell.execute_reply.started":"2025-08-12T16:30:47.918688Z","shell.execute_reply":"2025-08-12T16:31:43.710321Z"}},"outputs":[{"name":"stdout","text":"Records with existing images: 45600\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def parse_picture_data(picture_data_str):\n    \"\"\"Parse the picture data column into structured information\"\"\"\n    info = {\n        'year_range': 'Unknown',\n        'medium': 'Unknown',\n        'dimensions': 'Unknown',\n        'museum': 'Unknown',\n        'location': 'Unknown'\n    }\n    \n    if pd.isna(picture_data_str) or picture_data_str == '':\n        return info\n    \n    try:\n        # Extract year range (e.g., \"1574-88\", \"c. 1596\", \"1605-10\")\n        year_match = re.search(r'(?:c\\.\\s*)?(\\d{4}(?:-\\d{2,4})?)', str(picture_data_str))\n        if year_match:\n            info['year_range'] = year_match.group(1)\n        \n        # Extract medium (e.g., \"oil on canvas\", \"oil on wood\")\n        medium_match = re.search(r'(oil on (?:canvas|wood|panel)|tempera|fresco|watercolor|acrylic)', str(picture_data_str).lower())\n        if medium_match:\n            info['medium'] = medium_match.group(1)\n        \n        # Extract dimensions (e.g., \"68 x 95 cm\", \"114 x 130 cm\")\n        dim_match = re.search(r'(\\d+\\s*x\\s*\\d+(?:\\s*x\\s*\\d+)?\\s*cm)', str(picture_data_str))\n        if dim_match:\n            info['dimensions'] = dim_match.group(1)\n        \n        # Extract museum/collection info\n        parts = str(picture_data_str).split(',')\n        if len(parts) >= 3:\n            for part in parts[2:]:\n                part = part.strip().lower()\n                if any(keyword in part for keyword in ['museum', 'gallery', 'collection', 'church', 'palace', 'institute']):\n                    info['museum'] = part.title()\n                    break\n        \n        # Extract location (usually last part)\n        if len(parts) >= 2:\n            location = parts[-1].strip()\n            if len(location) > 2:\n                info['location'] = location.title()\n                \n    except Exception as e:\n        print(f\"Error parsing: {picture_data_str}, Error: {e}\")\n    \n    return info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:31:47.981010Z","iopub.execute_input":"2025-08-12T16:31:47.981370Z","iopub.status.idle":"2025-08-12T16:31:47.990998Z","shell.execute_reply.started":"2025-08-12T16:31:47.981344Z","shell.execute_reply":"2025-08-12T16:31:47.989679Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if 'picture data' in df.columns:\n    print(\"Parsing picture data...\")\n    df['parsed_data'] = df['picture data'].apply(parse_picture_data)\n    \n    # Extract individual fields\n    df['year_range'] = df['parsed_data'].apply(lambda x: x['year_range'])\n    df['medium'] = df['parsed_data'].apply(lambda x: x['medium'])\n    df['dimensions'] = df['parsed_data'].apply(lambda x: x['dimensions'])\n    df['museum'] = df['parsed_data'].apply(lambda x: x['museum'])\n    df['location'] = df['parsed_data'].apply(lambda x: x['location'])\n    \n    print(\"Picture data parsing complete!\")\n    print(f\"\\nYear ranges found: {df['year_range'].value_counts().head()}\")\n    print(f\"\\nMediums found: {df['medium'].value_counts().head()}\")\nelse:\n    # Create dummy columns if picture data doesn't exist\n    df['year_range'] = 'Unknown'\n    df['medium'] = 'Unknown'\n    df['dimensions'] = 'Unknown'\n    df['museum'] = 'Unknown'\n    df['location'] = 'Unknown'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:32:15.770470Z","iopub.execute_input":"2025-08-12T16:32:15.770784Z","iopub.status.idle":"2025-08-12T16:32:16.327884Z","shell.execute_reply.started":"2025-08-12T16:32:15.770763Z","shell.execute_reply":"2025-08-12T16:32:16.327071Z"}},"outputs":[{"name":"stdout","text":"Parsing picture data...\nPicture data parsing complete!\n\nYear ranges found: year_range\nUnknown    4757\n1650        352\n1660        292\n1630        276\n1304-06     263\nName: count, dtype: int64\n\nMediums found: medium\nUnknown          18408\noil on canvas    14866\nfresco            4020\noil on panel      3254\ntempera           3121\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Count paintings per artist\nartist_counts = df['artist'].value_counts()\nprint(f\"Artists with 3+ paintings: {len(artist_counts[artist_counts >= 3])}\")\nprint(f\"Total paintings by these artists: {artist_counts[artist_counts >= 3].sum()}\")\n\n# Keep only artists with 3 or more paintings\nartists_with_3plus = artist_counts[artist_counts >= 3].index\ndf_filtered = df[df['artist'].isin(artists_with_3plus)].reset_index(drop=True)\n\nprint(f\"Filtered dataset size: {len(df_filtered)}\")\nprint(f\"Number of unique artists: {df_filtered['artist'].nunique()}\")\n\n# Fill missing metadata with 'Unknown'\ncolumns_to_fill = ['artist', 'title', 'period', 'school', 'nationality', 'year_range', 'medium', 'museum', 'location']\nfor col in columns_to_fill:\n    if col in df_filtered.columns:\n        df_filtered[col] = df_filtered[col].fillna(\"Unknown\")\n\nprint(\"\\nMissing values after filling:\")\nprint(df_filtered[columns_to_fill].isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:32:42.610270Z","iopub.execute_input":"2025-08-12T16:32:42.611279Z","iopub.status.idle":"2025-08-12T16:32:42.792354Z","shell.execute_reply.started":"2025-08-12T16:32:42.611248Z","shell.execute_reply":"2025-08-12T16:32:42.791345Z"}},"outputs":[{"name":"stdout","text":"Artists with 3+ paintings: 3119\nTotal paintings by these artists: 42135\nFiltered dataset size: 42135\nNumber of unique artists: 3119\n\nMissing values after filling:\nartist         0\ntitle          0\nperiod         0\nschool         0\nnationality    0\nyear_range     0\nmedium         0\nmuseum         0\nlocation       0\ndtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def encode_labels(df, column):\n    le = LabelEncoder()\n    labels = le.fit_transform(df[column])\n    return labels, le\n\nprint(\"Encoding labels...\")\ndf_filtered['artist_label'], artist_le = encode_labels(df_filtered, 'artist')\ndf_filtered['title_label'], title_le = encode_labels(df_filtered, 'title')\ndf_filtered['period_label'], period_le = encode_labels(df_filtered, 'period')\ndf_filtered['school_label'], school_le = encode_labels(df_filtered, 'school')\ndf_filtered['nationality_label'], nationality_le = encode_labels(df_filtered, 'nationality')\ndf_filtered['year_label'], year_le = encode_labels(df_filtered, 'year_range')\ndf_filtered['medium_label'], medium_le = encode_labels(df_filtered, 'medium')\ndf_filtered['museum_label'], museum_le = encode_labels(df_filtered, 'museum')\ndf_filtered['location_label'], location_le = encode_labels(df_filtered, 'location')\n\nprint(f\"Number of artists: {len(artist_le.classes_)}\")\nprint(f\"Number of titles: {len(title_le.classes_)}\")\nprint(f\"Number of periods: {len(period_le.classes_)}\")\nprint(f\"Number of schools: {len(school_le.classes_)}\")\nprint(f\"Number of nationalities: {len(nationality_le.classes_)}\")\nprint(f\"Number of year ranges: {len(year_le.classes_)}\")\nprint(f\"Number of mediums: {len(medium_le.classes_)}\")\nprint(f\"Number of museums: {len(museum_le.classes_)}\")\nprint(f\"Number of locations: {len(location_le.classes_)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:33:03.268638Z","iopub.execute_input":"2025-08-12T16:33:03.268964Z","iopub.status.idle":"2025-08-12T16:33:03.441636Z","shell.execute_reply.started":"2025-08-12T16:33:03.268940Z","shell.execute_reply":"2025-08-12T16:33:03.440716Z"}},"outputs":[{"name":"stdout","text":"Encoding labels...\nNumber of artists: 3119\nNumber of titles: 25903\nNumber of periods: 12\nNumber of schools: 11\nNumber of nationalities: 26\nNumber of year ranges: 3403\nNumber of mediums: 7\nNumber of museums: 599\nNumber of locations: 1145\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class EnhancedArtDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row['image_path']\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n\n        labels = {\n            'artist': torch.tensor(row['artist_label']),\n            'title': torch.tensor(row['title_label']),\n            'period': torch.tensor(row['period_label']),\n            'school': torch.tensor(row['school_label']),\n            'nationality': torch.tensor(row['nationality_label']),\n            'year': torch.tensor(row['year_label']),\n            'medium': torch.tensor(row['medium_label']),\n            'museum': torch.tensor(row['museum_label']),\n            'location': torch.tensor(row['location_label'])\n        }\n\n        metadata = {\n            'title': row['title'],\n            'artist_name': row['artist'],\n            'period_name': row['period'],\n            'school_name': row['school'],\n            'nationality_name': row['nationality'],\n            'year_name': row['year_range'],\n            'medium_name': row['medium'],\n            'museum_name': row['museum'],\n            'location_name': row['location'],\n            'image_path': img_path\n        }\n        return image, labels, metadata","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:33:17.638625Z","iopub.execute_input":"2025-08-12T16:33:17.638940Z","iopub.status.idle":"2025-08-12T16:33:17.647512Z","shell.execute_reply.started":"2025-08-12T16:33:17.638918Z","shell.execute_reply":"2025-08-12T16:33:17.646254Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Optimized transforms for faster training\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Split dataset\ntrain_df, val_df = train_test_split(\n    df_filtered, \n    test_size=0.15, \n    stratify=df_filtered['artist_label'], \n    random_state=42\n)\n\ntrain_dataset = EnhancedArtDataset(train_df, transform=transform)\nval_dataset = EnhancedArtDataset(val_df, transform=transform)\n\n# Data loaders with optimizations\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n\nprint(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:33:31.134336Z","iopub.execute_input":"2025-08-12T16:33:31.134648Z","iopub.status.idle":"2025-08-12T16:33:31.227953Z","shell.execute_reply.started":"2025-08-12T16:33:31.134626Z","shell.execute_reply":"2025-08-12T16:33:31.226786Z"}},"outputs":[{"name":"stdout","text":"Train samples: 35814, Val samples: 6321\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"class EnhancedMultiTaskModel(nn.Module):\n    def __init__(self, num_artists, num_titles, num_periods, num_schools, num_nationalities, \n                 num_years, num_mediums, num_museums, num_locations):\n        super().__init__()\n        # Use smaller, faster backbone\n        self.backbone = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n        in_features = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Identity()\n        \n        # Shared feature layer for efficiency\n        self.shared_features = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3)\n        )\n        \n        # Classification heads\n        self.artist_head = nn.Linear(512, num_artists)\n        self.title_head = nn.Linear(512, num_titles)\n        self.period_head = nn.Linear(512, num_periods)\n        self.school_head = nn.Linear(512, num_schools)\n        self.nationality_head = nn.Linear(512, num_nationalities)\n        self.year_head = nn.Linear(512, num_years)\n        self.medium_head = nn.Linear(512, num_mediums)\n        self.museum_head = nn.Linear(512, num_museums)\n        self.location_head = nn.Linear(512, num_locations)\n\n    def forward(self, x):\n        backbone_features = self.backbone(x)\n        shared_features = self.shared_features(backbone_features)\n        \n        outputs = {\n            'artist': self.artist_head(shared_features),\n            'title': self.title_head(shared_features),\n            'period': self.period_head(shared_features),\n            'school': self.school_head(shared_features),\n            'nationality': self.nationality_head(shared_features),\n            'year': self.year_head(shared_features),\n            'medium': self.medium_head(shared_features),\n            'museum': self.museum_head(shared_features),\n            'location': self.location_head(shared_features),\n            'features': shared_features\n        }\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:33:52.122974Z","iopub.execute_input":"2025-08-12T16:33:52.123314Z","iopub.status.idle":"2025-08-12T16:33:52.133186Z","shell.execute_reply.started":"2025-08-12T16:33:52.123291Z","shell.execute_reply":"2025-08-12T16:33:52.132114Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Create model\nmodel = EnhancedMultiTaskModel(\n    len(artist_le.classes_), len(title_le.classes_), len(period_le.classes_),\n    len(school_le.classes_), len(nationality_le.classes_), len(year_le.classes_),\n    len(medium_le.classes_), len(museum_le.classes_), len(location_le.classes_)\n).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n\nprint(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:34:05.500225Z","iopub.execute_input":"2025-08-12T16:34:05.500530Z","iopub.status.idle":"2025-08-12T16:34:06.201590Z","shell.execute_reply.started":"2025-08-12T16:34:05.500498Z","shell.execute_reply":"2025-08-12T16:34:06.200515Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n100%|ââââââââââ| 20.5M/20.5M [00:00<00:00, 127MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Model created with 22,220,845 parameters\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def train_epoch(dataloader):\n    model.train()\n    total_loss = 0\n    correct_predictions = {\n        'artist': 0, 'title': 0, 'period': 0, 'school': 0, \n        'nationality': 0, 'year': 0, 'medium': 0, 'museum': 0, 'location': 0\n    }\n    total_samples = 0\n    \n    for images, labels, _ in tqdm(dataloader, desc=\"Training\"):\n        images = images.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(images)\n\n        # Calculate losses\n        losses = {}\n        for key in ['artist', 'title', 'period', 'school', 'nationality', 'year', 'medium', 'museum', 'location']:\n            losses[key] = criterion(outputs[key], labels[key].to(device))\n            \n            # Track accuracy\n            preds = outputs[key].argmax(dim=1)\n            correct_predictions[key] += (preds == labels[key].to(device)).sum().item()\n\n        # Weighted loss - prioritize artist and title\n        total_loss_batch = (\n            2.0 * losses['artist'] + \n            1.5 * losses['title'] + \n            0.5 * (losses['period'] + losses['school'] + losses['nationality']) +\n            0.3 * (losses['year'] + losses['medium'] + losses['museum'] + losses['location'])\n        )\n        \n        total_loss_batch.backward()\n        \n        # Gradient clipping for stability\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        total_loss += total_loss_batch.item()\n        total_samples += images.size(0)\n\n    # Calculate accuracies\n    accuracies = {key: correct/total_samples for key, correct in correct_predictions.items()}\n    \n    return total_loss / len(dataloader), accuracies\n\ndef validate_epoch(dataloader):\n    model.eval()\n    correct_predictions = {\n        'artist': 0, 'title': 0, 'period': 0, 'school': 0, \n        'nationality': 0, 'year': 0, 'medium': 0, 'museum': 0, 'location': 0\n    }\n    total_samples = 0\n\n    with torch.no_grad():\n        for images, labels, _ in tqdm(dataloader, desc=\"Validating\"):\n            images = images.to(device)\n            outputs = model(images)\n            \n            for key in correct_predictions.keys():\n                preds = outputs[key].argmax(dim=1)\n                correct_predictions[key] += (preds == labels[key].to(device)).sum().item()\n            \n            total_samples += images.size(0)\n\n    accuracies = {key: correct/total_samples for key, correct in correct_predictions.items()}\n    return accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:34:24.288379Z","iopub.execute_input":"2025-08-12T16:34:24.288693Z","iopub.status.idle":"2025-08-12T16:34:24.300366Z","shell.execute_reply.started":"2025-08-12T16:34:24.288672Z","shell.execute_reply":"2025-08-12T16:34:24.299479Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(\"Starting training...\")\nepochs = 1\n\nfor epoch in range(epochs):\n    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n    train_loss, train_acc = train_epoch(train_loader)\n    val_acc = validate_epoch(val_loader)\n    \n    print(f\"Train Loss: {train_loss:.4f}\")\n    print(\"Train Accuracies:\")\n    for key, acc in train_acc.items():\n        print(f\"  {key.capitalize()}: {acc:.3f}\")\n    print(\"Validation Accuracies:\")\n    for key, acc in val_acc.items():\n        print(f\"  {key.capitalize()}: {acc:.3f}\")\n\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:34:39.733674Z","iopub.execute_input":"2025-08-12T16:34:39.733956Z","iopub.status.idle":"2025-08-12T18:11:45.987454Z","shell.execute_reply.started":"2025-08-12T16:34:39.733938Z","shell.execute_reply":"2025-08-12T18:11:45.982686Z"}},"outputs":[{"name":"stdout","text":"Starting training...\n\nEpoch 1/1\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|ââââââââââ| 1120/1120 [1:33:15<00:00,  5.00s/it]\nValidating: 100%|ââââââââââ| 198/198 [03:50<00:00,  1.17s/it]","output_type":"stream"},{"name":"stdout","text":"Train Loss: 33.9791\nTrain Accuracies:\n  Artist: 0.063\n  Title: 0.045\n  Period: 0.435\n  School: 0.877\n  Nationality: 0.506\n  Year: 0.099\n  Medium: 0.677\n  Museum: 0.638\n  Location: 0.172\nValidation Accuracies:\n  Artist: 0.098\n  Title: 0.056\n  Period: 0.525\n  School: 0.911\n  Nationality: 0.560\n  Year: 0.104\n  Medium: 0.763\n  Museum: 0.665\n  Location: 0.199\nTraining complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(\"Saving model and encoders...\")\ntorch.save(model.state_dict(), \"enhanced_art_model.pth\")\n\n# Save all encoders\nencoders = {\n    'artist': artist_le,\n    'title': title_le,\n    'period': period_le,\n    'school': school_le,\n    'nationality': nationality_le,\n    'year': year_le,\n    'medium': medium_le,\n    'museum': museum_le,\n    'location': location_le\n}\n\nfor name, encoder in encoders.items():\n    pickle.dump(encoder, open(f'{name}_le.pkl', 'wb'))\n\n# Create mappings for local testing\ntitle_mapping = dict(zip(df_filtered['image_path'], df_filtered['title']))\nartist_mapping = dict(zip(df_filtered['image_path'], df_filtered['artist']))\n\npickle.dump(title_mapping, open('title_mapping.pkl', 'wb'))\npickle.dump(artist_mapping, open('artist_mapping.pkl', 'wb'))\n\nprint(\"Model and encoders saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:11:58.105827Z","iopub.execute_input":"2025-08-12T18:11:58.106232Z","iopub.status.idle":"2025-08-12T18:11:58.583834Z","shell.execute_reply.started":"2025-08-12T18:11:58.106194Z","shell.execute_reply":"2025-08-12T18:11:58.582790Z"}},"outputs":[{"name":"stdout","text":"Saving model and encoders...\nModel and encoders saved!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(\"Building embedding database...\")\n\ndef build_embedding_db(dataloader):\n    embedding_db = {}\n    model.eval()\n    with torch.no_grad():\n        for images, _, metadata in tqdm(dataloader, desc=\"Building embeddings\"):\n            images = images.to(device)\n            outputs = model(images)\n            features = outputs['features']\n            \n            # Handle metadata properly\n            batch_size = len(images)\n            for i in range(batch_size):\n                meta_dict = {}\n                for key, value_list in metadata.items():\n                    meta_dict[key] = value_list[i]\n                embedding_db[meta_dict['image_path']] = features[i].cpu().numpy()\n    return embedding_db\n\nembedding_db = build_embedding_db(train_loader)\nnp.save(\"enhanced_embedding_db.npy\", embedding_db)\nprint(f\"Embedding database saved with {len(embedding_db)} entries.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:12:20.274715Z","iopub.execute_input":"2025-08-12T18:12:20.276134Z","iopub.status.idle":"2025-08-12T18:32:42.454381Z","shell.execute_reply.started":"2025-08-12T18:12:20.276058Z","shell.execute_reply":"2025-08-12T18:32:42.453077Z"}},"outputs":[{"name":"stdout","text":"Building embedding database...\n","output_type":"stream"},{"name":"stderr","text":"Building embeddings: 100%|ââââââââââ| 1120/1120 [20:21<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"Embedding database saved with 35796 entries.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def compute_authenticity_score(new_embedding, known_embeddings):\n    if len(known_embeddings) == 0:\n        return 0\n    sims = cosine_similarity(new_embedding.reshape(1, -1), known_embeddings)\n    return sims.max()\n\ndef predict_enhanced(image_path, threshold=0.75):\n    model.eval()\n    image = Image.open(image_path).convert(\"RGB\")\n    input_tensor = transform(image).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        outputs = model(input_tensor)\n        \n        predictions = {}\n        encoders_dict = {\n            'artist': artist_le, 'title': title_le, 'period': period_le,\n            'school': school_le, 'nationality': nationality_le, 'year': year_le,\n            'medium': medium_le, 'museum': museum_le, 'location': location_le\n        }\n        \n        for key, encoder in encoders_dict.items():\n            probs = torch.softmax(outputs[key], dim=1).cpu().numpy()[0]\n            pred_idx = probs.argmax()\n            predictions[key] = {\n                'name': encoder.classes_[pred_idx],\n                'confidence': probs[pred_idx]\n            }\n\n        # Context-aware title prediction\n        predicted_artist = predictions['artist']['name']\n        artist_titles = df_filtered[df_filtered['artist'] == predicted_artist]['title'].unique()\n        \n        if len(artist_titles) > 0:\n            title_probs = torch.softmax(outputs['title'], dim=1).cpu().numpy()[0]\n            filtered_scores = []\n            for title in artist_titles:\n                if title in title_le.classes_:\n                    title_idx = list(title_le.classes_).index(title)\n                    filtered_scores.append((title, title_probs[title_idx]))\n            \n            if filtered_scores:\n                best_title, best_score = max(filtered_scores, key=lambda x: x[1])\n                predictions['title'] = {\n                    'name': best_title,\n                    'confidence': best_score,\n                    'method': 'context_aware'\n                }\n\n        # Authenticity check\n        known_embeddings = np.array(list(embedding_db.values()))\n        new_embedding = outputs['features'].cpu().numpy()\n        authenticity_score = compute_authenticity_score(new_embedding, known_embeddings)\n        authenticity_msg = \"Likely Authentic\" if authenticity_score >= threshold else \"Suspicious / Possibly Forged\"\n\n        print(\"=\" * 60)\n        print(f\"IMAGE: {image_path}\")\n        print(\"=\" * 60)\n        print(f\" TITLE: {predictions['title']['name']}\")\n        print(f\"   Confidence: {predictions['title']['confidence']*100:.1f}%\")\n        print(f\" ARTIST: {predictions['artist']['name']}\")\n        print(f\"   Confidence: {predictions['artist']['confidence']*100:.1f}%\")\n        print(f\" YEAR: {predictions['year']['name']}\")\n        print(f\"   Confidence: {predictions['year']['confidence']*100:.1f}%\")\n        print(f\" MEDIUM: {predictions['medium']['name']}\")\n        print(f\"   Confidence: {predictions['medium']['confidence']*100:.1f}%\")\n        print(f\" SCHOOL: {predictions['school']['name']}\")\n        print(f\"   Confidence: {predictions['school']['confidence']*100:.1f}%\")\n        print(f\" NATIONALITY: {predictions['nationality']['name']}\")\n        print(f\"   Confidence: {predictions['nationality']['confidence']*100:.1f}%\")\n        print(f\" MUSEUM: {predictions['museum']['name']}\")\n        print(f\"   Confidence: {predictions['museum']['confidence']*100:.1f}%\")\n        print(f\" LOCATION: {predictions['location']['name']}\")\n        print(f\"   Confidence: {predictions['location']['confidence']*100:.1f}%\")\n        print(f\" AUTHENTICITY: {authenticity_score:.2f} ({authenticity_msg})\")\n        print(\"=\" * 60)\n\nprint(\"Setup complete! Use predict_enhanced('image_path') to test the model.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:33:53.693183Z","iopub.execute_input":"2025-08-12T18:33:53.693560Z","iopub.status.idle":"2025-08-12T18:33:53.710996Z","shell.execute_reply.started":"2025-08-12T18:33:53.693517Z","shell.execute_reply":"2025-08-12T18:33:53.709929Z"}},"outputs":[{"name":"stdout","text":"Setup complete! Use predict_enhanced('image_path') to test the model.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"predict_enhanced('/kaggle/input/historic-art/complete/artwork/0.jpg')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T18:46:06.938015Z","iopub.execute_input":"2025-08-12T18:46:06.938407Z","iopub.status.idle":"2025-08-12T18:46:07.586781Z","shell.execute_reply.started":"2025-08-12T18:46:06.938383Z","shell.execute_reply":"2025-08-12T18:46:07.585860Z"}},"outputs":[{"name":"stdout","text":"============================================================\nIMAGE: /kaggle/input/historic-art/complete/artwork/0.jpg\n============================================================\n TITLE: adoration of the shepherds\n   Confidence: 0.8%\n ARTIST: RUBENS, Peter Paul\n   Confidence: 1.3%\n YEAR: Unknown\n   Confidence: 11.7%\n MEDIUM: oil on canvas\n   Confidence: 72.2%\n SCHOOL: painter\n   Confidence: 95.9%\n NATIONALITY: Italian\n   Confidence: 23.9%\n MUSEUM: Unknown\n   Confidence: 33.8%\n LOCATION: Private Collection\n   Confidence: 26.3%\n AUTHENTICITY: 1.00 (Likely Authentic)\n============================================================\n","output_type":"stream"}],"execution_count":30}]}